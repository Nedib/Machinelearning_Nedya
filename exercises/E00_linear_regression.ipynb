{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a href=\"https://colab.research.google.com/github/kokchun/Machine-learning-AI22/blob/main/Exercises/E00_linear_regression.ipynb\" target=\"_parent\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; to see hints and answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Linear regression exercises\n",
    "\n",
    "---\n",
    "These are introductory exercises in Machine learning with focus in **linear regression** .\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Note</b> all datasets used in this exercise can be found under Data folder of the course Github repo</p>\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Note</b> that in cases when you start to repeat code, try not to. Create functions to reuse code instead. </p>\n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Remember</b> to use <b>descriptive variable, function, index </b> and <b> column names</b> in order to get readable code </p>\n",
    "\n",
    "The number of stars (\\*), (\\*\\*), (\\*\\*\\*) denotes the difficulty level of the task\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Simulate phone dataset (*)\n",
    "\n",
    "We want to simulate data $(x,y)$ to represent cost for phone subscriptions, with: \n",
    "\n",
    "- $x$ - called minutes per month\n",
    "- $y$ - SEK per month \n",
    "\n",
    "&nbsp; a) Use ```numpy.random.normal()``` to simulate a dataset with the following requirements:(*)\n",
    "- set a seed to 42 (for reproducibility and reference)\n",
    "- simulate 400 x-values from the r.v. $X \\sim \\mathcal{N}(100, 100)$ \n",
    "- take absolute value of these x-values\n",
    "- simulate noise 400 noise values from r.v. $\\epsilon \\sim \\mathcal{N(0, 50)}$ \n",
    "- Let $y = 2x+25+\\epsilon$\n",
    "- plot the data set \n",
    "\n",
    "&nbsp; b) Now we want to remove some outliers according to this assumption: (*)\n",
    "- no one talks more than 300 min using this type of subscription\n",
    "- no ones costs can be negative\n",
    "- plot the new dataset\n",
    "- also plot ground truth using the true parameters $\\beta_0 = 25, \\beta_1 = 2$\n",
    "\n",
    "&nbsp; c) Insert the values into a DataFrame (*)\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "<img src=\"../assets/simulated_phone_dataset_0.png\" height=\"200\"/>\n",
    "\n",
    "a) \n",
    "\n",
    "Number of points x â‰¥ 300 min: 8\n",
    "\n",
    "Number of points y < 0 kr: 6\n",
    "\n",
    "\n",
    "b)\n",
    "\n",
    "Length of x, outliers removed 386\n",
    "\n",
    "Length of y, outliers removed 386\n",
    "\n",
    "c)\n",
    "\n",
    "df.head()\n",
    "\n",
    "|    |   Minutes |     Cost |\n",
    "|---:|----------:|---------:|\n",
    "|  0 |   59.4428 | 168.721  |\n",
    "|  1 |   40.0625 |  98.2118 |\n",
    "|  2 |  100.524  | 258.433  |\n",
    "|  3 |  104.698  | 310.548  |\n",
    "|  4 |   54.9935 | 123.279  |\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# 400 random normally distributed points with mu = 100, sigma = 100\n",
    "X = abs(np.random.normal(100, 100, 400))\n",
    "print(f\"X:\\n{X[:4]}\\n{max(X) = }\\n{min(X) = }\\n\")\n",
    "\n",
    "# 400 random normally distributed noise points with mu = 0, sigma = 50\n",
    "epsilon = np.random.normal(0, 50, 400)\n",
    "print(f\"epsilon:\\n{epsilon[:4]}\\n{max(epsilon) = }\\n{min(epsilon) = }\\n\")\n",
    "\n",
    "beta_0 = 25 # intercept\n",
    "beta_1 = 2  # slope\n",
    "\n",
    "# y as a function of X with random noise added\n",
    "y = beta_0 + beta_1 * X + epsilon\n",
    "\n",
    "print(f\"y:\\n{y[:4]}\\n{max(y) = }\\n{min(y) = }\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = X, y = y, label = \"Datapoints\")\n",
    "plt.axhline(y = 0, color = \"r\", linestyle = \"--\", label = \"Min Cost Cutoff\")\n",
    "plt.axvline(x = 300, color = \"g\", linestyle = \"-.\", label = \"Max Time Cutoff\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B\n",
    "\n",
    "# getting indices where time is above 300\n",
    "itemindex = np.where(X > 300)\n",
    "\n",
    "# times above 300\n",
    "X[itemindex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting indices of X outliers from both X and y\n",
    "X = np.delete(X, itemindex)\n",
    "y = np.delete(y, itemindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting indices where cost is below 0\n",
    "itemindex = np.where(y < 0)\n",
    "\n",
    "# costs below 0\n",
    "y[itemindex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting indices of y outliers from both X and y\n",
    "X = np.delete(X, itemindex)\n",
    "y = np.delete(y, itemindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no more values below 0 cost or above 300 time\n",
    "np.where(X > 300), np.where(y < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = X, y = y, label = \"Datapoints\", line_kws={\"color\": \"black\", \"label\": \"Based on Entire Dataset\"})\n",
    "sns.lineplot(x = X, y = 2 * X + 25, color = \"red\", label = \"OLS Prediction\")\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df[\"X\"] = X\n",
    "df[\"y\"] = y\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train|test split (*)\n",
    "\n",
    "Before moving on with linear regression we shall first perform a train-test-split. \n",
    "\n",
    "&nbsp; a) Create a train-test-split function with the following call signature: (*)\n",
    "\n",
    "```py\n",
    "def train_test_split(X: pd.DataFrame, y: pd.DataFrame, train_fraction=.7: float, random_state=42: int, replace=False: bool) -> tuple\n",
    "```\n",
    "\n",
    "that returns the tuple:\n",
    "```\n",
    "(X_train, X_test, y_train, y_test)\n",
    "```\n",
    "\n",
    "&nbsp; b) Now use this to split up your data into a training set and test set. Check manually that the split is performed correctly. (*)\n",
    "\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Hint</summary>\n",
    "\n",
    "b) Check the length of each set, and check the indices of the sorted sets that they don't overlap and are not missing. Also check that they sum up to what you expect.\n",
    "\n",
    "</details>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "Using default 0.7: \n",
    "- length of X_train: 270\n",
    "- length of X_test: 116\n",
    "- length of y_train: 270\n",
    "- length of X_test: 116\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(X, y, train_fraction=0.7, random_state=42, replace=False) -> tuple:\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Calculate the number of indices for training data\n",
    "    n = int(len(X) * train_fraction)\n",
    "\n",
    "    # Generate an array of random indices\n",
    "    indices = np.random.choice(len(X), size=n, replace=replace)\n",
    "\n",
    "    # Split X and y into train and test data based on the indices array\n",
    "    X_train = X[indices]\n",
    "    X_test = X[np.in1d(np.arange(len(X)), indices, invert=True)]\n",
    "    y_train = y[indices]\n",
    "    y_test = y[np.in1d(np.arange(len(y)), indices, invert=True)]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train, X_test, y_train, y_test = test_test_test(X, y)\n",
    "\n",
    "# checking dimensions to make sure everything looks right\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple linear regression with normal equation (*)\n",
    "\n",
    "Use the normal equation for simple linear regression to solve for the coefficients $\\hat{\\beta} = (\\beta_0, \\beta_1)$. Note that you should only use the training data to fit the regression line, and not data from the test set. Plot the the regression line, together with ground truth and training data. \n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Hint</summary>\n",
    "\n",
    "It is important to keep track of the shapes of the vectors, matrices in order for matrix multiplication matmul \"@\" to work correctly. Also, if you have series object, you need to convert it to numpy. \n",
    "\n",
    "</details>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "\n",
    "<img src=\"../assets/Reg_line_normal_eq.png\" height=\"200\"/>\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a column of ones for coming calculation\n",
    "ones = np.ones((len(X_train),))\n",
    "X_train_matrix = np.stack((ones, X_train), axis= -1)\n",
    "\n",
    "X_train_matrix[:3], X_train_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a column of ones for coming calculation\n",
    "ones = np.ones((len(X_test),))\n",
    "X_test_matrix = np.stack((ones, X_test), axis= -1)\n",
    "\n",
    "X_test_matrix[:3], X_test_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function for estimating unknown parameters (beta vector)\n",
    "OLS = lambda X, y: np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "# using function to estimate beta_hat based on training data\n",
    "beta_hat = OLS(X_train_matrix, y_train)\n",
    "\n",
    "beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at dimensions to make sure everything is ready to move on\n",
    "beta_hat.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction and evaluation (*)\n",
    "\n",
    "&nbsp; a) Use your model to make prediction on testing data. Plot the prediction cost against X_test, and y_test against X_test. (*)\n",
    "\n",
    "&nbsp; b) Calculate MAE, MSE, RMSE (*)\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Hint</summary>\n",
    "\n",
    "Calculate y_pred from X_test and use y_test and y_pred to compute different evaluation metrics.\n",
    "\n",
    "Careful with dimensions when computing the evaluation metrics, else it can be catastrophical logical errors due to numpy broadcasting feature.\n",
    "\n",
    "Note that after you have calculate the error metrics on test data you are not allowed to change any parameters to make the line fit better to the testing data.\n",
    "\n",
    "</details>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "a) \n",
    "\n",
    "<img src=\"../assets/eval_simple_lin_reg.png\" height=\"200\"/>\n",
    "\n",
    "b)\n",
    "\n",
    "Mean absolute error on testing data: 36.97 kr\n",
    "\n",
    "Mean squared error on testing data: 2374 kr^2\n",
    "\n",
    "Root mean squared error on testing data: 48.72 kr\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function\n",
    "predict = lambda x, beta: np.dot(x, beta)\n",
    "\n",
    "# storing predictions to y_pred, reshaping from (115,1) to (115,)\n",
    "y_pred = predict(X_test_matrix, beta_hat)\n",
    "\n",
    "y_pred[:3], y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = X_test, y = y_test, color = \"blue\", alpha = 0.6, label = \"True Values\")\n",
    "sns.scatterplot(x = X_test, y = y_pred, color = \"red\", alpha = 0.6, label = \"Predicted Values\")\n",
    "sns.lineplot(x = X_test, y = y_pred, color = \"black\", zorder = 0, label = \"Regression Line\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B\n",
    "m = len(y_test)\n",
    "\n",
    "mean_absolute_error = np.sum(np.abs(y_test - y_pred)) / m\n",
    "\n",
    "mean_squared_error = np.sum((y_test - y_pred) ** 2) / m\n",
    "\n",
    "root_mean_squared_error = np.sqrt(mean_squared_error)\n",
    "\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error}\")\n",
    "print(f\"MSE: {mean_squared_error}\")\n",
    "print(f\"RMSE: {root_mean_squared_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulate more explanatory variables (\\*)\n",
    "\n",
    "Now we will simulate the explanatory variables for minutes, text messages and amount of surf. For reference and reproducibility use numpy random seed 42. Assume there is:\n",
    "\n",
    "- mean start cost: 25kr\n",
    "- mean cost per minute: 2kr\n",
    "- mean cost per sms: 50 Ã¶re\n",
    "- mean cost per GB: 50kr\n",
    "\n",
    "Then the model for the cost will be:\n",
    "$y = 25 + 2x_1 + 0.5x_2 + 50x_3 + \\epsilon$, where\n",
    "\n",
    "- $x_i$ sampled from r.v. $X_i$ for $i = \\{1,2,3\\}$\n",
    "- $X_1 \\sim |\\mathcal{N}(100,100)|$, (absolute value)\n",
    "- $X_2 \\sim \\mathcal{U}(0,50)$, (discrete uniform distribution)\n",
    "- $X_3 \\sim |\\mathcal{N}(0,2)|$,\n",
    "- $\\epsilon \\sim \\mathcal{N}(0,50)$\n",
    "\n",
    "&nbsp; a) Simulate 10000 samples of each of $x_1, x_2, x_3$ and $y$ and save them in a DataFrame. Also add an intercept column containing ones. (\\*)\n",
    "\n",
    "&nbsp; b) Make histograms for each of the explanatory variables $x_1, x_2, x_3$ and the response variable $y$ (\\*)\n",
    "\n",
    "&nbsp; c) Clean the data using the following constraints (\\*)\n",
    "\n",
    "- surf should be less than 4\n",
    "- minutes should be less than 300\n",
    "- cost should be larger than 0\n",
    "\n",
    "&nbsp; d) Make new histograms for the variables. (\\*)\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Hint</summary>\n",
    "Your data analysis skill toolbox together with statistics and linear algebra skills are getting quite handy here.\n",
    "\n",
    "</details>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Answer</summary>\n",
    "\n",
    "a)\n",
    "\n",
    "|      | Intercept | Minutes | SMS | Surf (GB) |    Cost |\n",
    "| ---: | --------: | ------: | --: | --------: | ------: |\n",
    "|    0 |         1 | 149.671 |  41 |   2.26301 | 502.396 |\n",
    "|    1 |         1 | 86.1736 |  16 | 0.0315695 | 179.072 |\n",
    "|  ... |       ... |     ... | ... |       ... |     ... |\n",
    "| 9318 |         1 | 149.577 |  31 |   3.43929 | 536.176 |\n",
    "| 9319 |         1 | 164.439 |  43 |   1.40641 | 406.674 |\n",
    "\n",
    "b)\n",
    "\n",
    "<img src=\"../assets/hist_variables.png\" height=\"200\"/>\n",
    "\n",
    "d)\n",
    "\n",
    "<img src=\"../assets/hist_var_cleaned.png\" height=\"200\"/>\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_sample(sample_size = 10000):\n",
    "\n",
    "    np.random.seed(42) # for reproducability\n",
    "\n",
    "    x1 = np.abs(np.random.normal(loc = 100, scale = 100, size = sample_size))\n",
    "    x2 = np.random.uniform(low = 0, high = 50, size = sample_size)\n",
    "    x3 = np.abs(np.random.normal(loc = 0, scale = 2, size = sample_size))\n",
    "    epsilon = np.random.normal(loc = 0, scale = 50, size = sample_size)\n",
    "\n",
    "    beta_0 = 25\n",
    "    beta_1 = 2\n",
    "    beta_2 = 0.5\n",
    "    beta_3 = 50\n",
    "\n",
    "    y = beta_0 + beta_1 * x1 + beta_2 * x2 + beta_3 * x3 + epsilon\n",
    "\n",
    "    return x1, x2, x3, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, x3, y = simulate_sample()\n",
    "\n",
    "print(f\"y:\\n{y[:3]}\\n{y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B,\n",
    "fig, ax = plt.subplots(1, 3, figsize = (12, 4))\n",
    "variables = [\"Minute\", \"Text Message\", \"GB\"]\n",
    "\n",
    "for i, x in enumerate([x1, x2, x3]):\n",
    "    sns.histplot(x = x, y = y, ax = ax[i])\n",
    "    ax[i].set_title(f\"Cost per {variables[i]}\")\n",
    "    ax[i].set_xlabel(variables[i] + \"s\")\n",
    "\n",
    "ax[0].set_ylabel(\"Cost\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C\n",
    "def clean_data(x1, x2, x3, y):\n",
    "    # minutes must be less than 300\n",
    "    itemindex = np.where(x1 >= 300)\n",
    "\n",
    "    x1 = np.delete(x1, itemindex)\n",
    "    x2 = np.delete(x2, itemindex)\n",
    "    x3 = np.delete(x3, itemindex)\n",
    "    y = np.delete(y, itemindex)\n",
    "\n",
    "    # GB must be less than 4\n",
    "    itemindex = np.where(x3 >= 4)\n",
    "\n",
    "    x1 = np.delete(x1, itemindex)\n",
    "    x2 = np.delete(x2, itemindex)\n",
    "    x3 = np.delete(x3, itemindex)\n",
    "    y = np.delete(y, itemindex)\n",
    "\n",
    "    # cost must be greater than 0\n",
    "    itemindex = np.where(y <= 0)\n",
    "\n",
    "    x1 = np.delete(x1, itemindex)\n",
    "    x2 = np.delete(x2, itemindex)\n",
    "    x3 = np.delete(x3, itemindex)\n",
    "    y = np.delete(y, itemindex)\n",
    "\n",
    "    return x1, x2, x3, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D\n",
    "fig, ax = plt.subplots(1, 3, figsize = (12, 4))\n",
    "variables = [\"Minute\", \"Text Message\", \"GB\"]\n",
    "\n",
    "for i, x in enumerate([x1, x2, x3]):\n",
    "    sns.histplot(x = x, y = y, ax = ax[i])\n",
    "    ax[i].set_title(f\"Cost per {variables[i]}\")\n",
    "    ax[i].set_xlabel(variables[i] + \"s\")\n",
    "\n",
    "ax[0].set_ylabel(\"Cost\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multiple linear regression (*)\n",
    "\n",
    "&nbsp; a) Perform a train|test split with 0.8 of the data for training. (*)\n",
    "\n",
    "&nbsp; b) Use the normal equation to compute $\\hat{\\beta}$ (*)\n",
    "\n",
    "&nbsp; c) Predict on the test data and compute MAE, MSE and RMSE. (*)\n",
    "\n",
    "&nbsp; d) Now repeat 4a), 4c), 5a), 5b) using 10, 100, 1000, 10000, 100000, 1000000 samples, and calculate RMSE for each of these simulations. Plot the RMSE against sample size. (**)\n",
    "\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Hint</summary>\n",
    "\n",
    "It is important to keep track of the shapes of the vectors, matrices in order for matrix multiplication matmul \"@\" to work correctly. Also, if you have series object, you need to convert it to numpy. \n",
    "\n",
    "</details>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "\n",
    "\n",
    "<img src=\"../assets/RMSE_simulation.png\" height=\"200\"/>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_ones():\n",
    "    # adding a column of ones for coming calculation\n",
    "    ones = np.ones((len(x1),))\n",
    "    X = np.stack((ones, x1, x2, x3), axis= -1)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = insert_ones()\n",
    "\n",
    "X[:3], X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = test_test_test(X, y, train_fraction = 0.8)\n",
    "\n",
    "# checking dimensions to make sure everything looks right\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B\n",
    "# looking at dimensions to make sure everything is ready to move on\n",
    "beta_hat.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C\n",
    "y_pred = predict(X_test, beta_hat)\n",
    "\n",
    "y_pred[:3], y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining functions to calculate MAE, MSE, RMSE\n",
    "mean_absolute_error = lambda y_test, y_pred: np.sum(np.abs(y_test - y_pred)) / len(y_test)\n",
    "mean_squared_error = lambda y_test, y_pred: np.sum((y_test - y_pred) ** 2) / len(y_test)\n",
    "root_mean_squared_error = lambda y_test, y_pred: np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred)}\")\n",
    "print(f\"MAE: {mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"MAE: {root_mean_squared_error(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D\n",
    "samples = [10, 100, 1000, 10000, 100000, 1000000]\n",
    "RMSE_list = []\n",
    "\n",
    "for i in samples:\n",
    "    x1, x2, x3, y = simulate_sample(sample_size = i)\n",
    "    x1, x2, x3, y = clean_data(x1, x2, x3, y)\n",
    "    X = insert_ones()\n",
    "    X_train, X_test, y_train, y_test = test_test_test(X, y, train_fraction = 0.8)\n",
    "    beta_hat = OLS(X_train, y_train)\n",
    "    y_pred = predict(X_test, beta_hat)\n",
    "    RMSE = root_mean_squared_error(y_test, y_pred)\n",
    "    RMSE_list.append(RMSE)\n",
    "    \n",
    "sns.lineplot(x = samples, y = RMSE_list)\n",
    "plt.suptitle(\"RMSE as Sample Size Increases\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xlabel(\"Sample Size\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Kokchun Giang\n",
    "\n",
    "[LinkedIn][linkedIn_kokchun]\n",
    "\n",
    "[GitHub portfolio][github_portfolio]\n",
    "\n",
    "[linkedIn_kokchun]: https://www.linkedin.com/in/kokchungiang/\n",
    "[github_portfolio]: https://github.com/kokchun/Portfolio-Kokchun-Giang\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0da836a34428266995a795f1e1e27b816fa1c02f148d9728b3fbbbc5459afca6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
